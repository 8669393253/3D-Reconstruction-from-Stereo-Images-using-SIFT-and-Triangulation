1. Feature Detection and Matching (SIFT & FLANN):
   - SIFT (Scale-Invariant Feature Transform) is used to detect keypoints in the images and compute descriptors. SIFT is invariant to scale, rotation, and some affine transformations, making it robust for matching features between two images from different angles.
   - FLANN (Fast Library for Approximate Nearest Neighbors) is used to match the SIFT descriptors efficiently between two images. A ratio test is applied to discard bad matches and keep only the good ones, improving the quality of the matching process.

2. Camera Calibration:
   - The script uses a dummy camera matrix with a basic intrinsic configuration (focal length and principal point). In a real-world scenario, camera calibration is essential to obtain the actual intrinsic parameters (focal length, principal point, distortion coefficients).
   - The camera matrix is used for projection during triangulation, so accurate intrinsic parameters will yield better results in 3D reconstruction.

3. 3D Triangulation:
   - After detecting and matching the keypoints between two images, triangulation is used to calculate the 3D positions of the matched points.
   - The code uses simplified assumptions for camera motion: it assumes an identity rotation matrix (`R = I`) and an arbitrary translation vector (`T = [1, 0, 0]`). In practice, these values should be computed from the fundamental matrix or obtained from stereo calibration.
   - The triangulatePoints() function from OpenCV is used to perform the triangulation. This function calculates the 3D coordinates based on the matched 2D points and the camera projection matrices.

4. Visualization:
   - The keypoint matches are visualized in 2D using `cv2.drawMatches()`, where lines are drawn between matching points in the two images.
   - The 3D points are visualized using `matplotlib`'s 3D plotting capabilities, showing the reconstructed 3D scene based on the triangulated points.

5. Dependencies:
   - The project relies on three key Python libraries:
     - OpenCV: for image processing, feature detection, and triangulation.
     - NumPy: for handling matrix and array operations.
     - Matplotlib: for visualizing the keypoint matches and 3D reconstruction.
   - The required packages are listed in the `requirements.txt` file for easy installation.

6. Limitations and Assumptions:
   - Simplified Camera Model: The camera matrix is set up with arbitrary values, and there is no real stereo calibration used. In practice, you would need to calibrate the cameras and compute the fundamental matrix to get an accurate relative pose (rotation and translation).
   - No Distortion Model: The code assumes no lens distortion (distortion coefficients are set to zero). In real-world scenarios, lens distortion can significantly affect the accuracy of feature matching and triangulation, and you would need to correct for this during calibration.
   - Relative Camera Pose: The code assumes a simple transformation between the two camera positions (identity rotation and translation vector), but in real applications, you would need stereo calibration to estimate this accurately.

7. Potential Improvements:
   - Stereo Calibration: Instead of using an identity rotation matrix and an arbitrary translation, you can compute the relative camera pose from the fundamental matrix obtained from the matched keypoints and perform stereo calibration.
   - Camera Calibration: To get better 3D results, use real intrinsic camera parameters by performing a **camera calibration** procedure (e.g., using a checkerboard pattern) to accurately estimate the focal length, principal point, and distortion coefficients.
   - Bundle Adjustment: After triangulation, **bundle adjustment can be used to refine the 3D points and camera parameters by optimizing the entire reconstruction pipeline.

8. Output:
   - Feature Matches: The first output is a 2D image showing the keypoints from the two images, with lines connecting matching keypoints. This helps visualize how the features are matched.
   - 3D Reconstruction: The second output is a 3D scatter plot of the triangulated points, showing a rough reconstruction of the scene. This helps to visualize the spatial relationship between the matched keypoints in the 3D space.
